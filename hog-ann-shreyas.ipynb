{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5787354,"sourceType":"datasetVersion","datasetId":3324878},{"sourceId":7270165,"sourceType":"datasetVersion","datasetId":4214396},{"sourceId":7512912,"sourceType":"datasetVersion","datasetId":4375886}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-10T04:38:57.048329Z","iopub.execute_input":"2024-03-10T04:38:57.049194Z","iopub.status.idle":"2024-03-10T04:38:58.389509Z","shell.execute_reply.started":"2024-03-10T04:38:57.049156Z","shell.execute_reply":"2024-03-10T04:38:58.388357Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"from scipy.spatial.qhull import QhullError\nfrom scipy import spatial\nspatial.QhullError = QhullError","metadata":{"execution":{"iopub.status.busy":"2024-03-10T04:38:58.391148Z","iopub.execute_input":"2024-03-10T04:38:58.391464Z","iopub.status.idle":"2024-03-10T04:38:58.396963Z","shell.execute_reply.started":"2024-03-10T04:38:58.391434Z","shell.execute_reply":"2024-03-10T04:38:58.395918Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_42/2927579722.py:1: DeprecationWarning: Please use `QhullError` from the `scipy.spatial` namespace, the `scipy.spatial.qhull` namespace is deprecated.\n  from scipy.spatial.qhull import QhullError\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import accuracy_score\nfrom category_encoders import OrdinalEncoder","metadata":{"execution":{"iopub.status.busy":"2024-03-10T04:38:58.398151Z","iopub.execute_input":"2024-03-10T04:38:58.398415Z","iopub.status.idle":"2024-03-10T04:38:59.589730Z","shell.execute_reply.started":"2024-03-10T04:38:58.398388Z","shell.execute_reply":"2024-03-10T04:38:59.588619Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\n\ndef get_image_paths(folder_path):\n    image_paths = []\n    for filename in os.listdir(folder_path):\n        if filename.endswith(('.png', '.jpg', '.jpeg')):\n            image_path = os.path.join(folder_path, filename)\n            image_paths.append(image_path)\n    return image_paths\n\nif __name__ == \"__main__\":\n    # Specify input folders\n    input_folder_blacksigatoka = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka\"\n    input_folder_furasiumwilt = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt\"\n    input_folder_cordana = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana\"\n\n    # Get image paths for each class\n    image_paths_blacksigatoka = get_image_paths(input_folder_blacksigatoka)\n    image_paths_furasiumwilt = get_image_paths(input_folder_furasiumwilt)\n    image_paths_cordana = get_image_paths(input_folder_cordana)\n\n    # Print the first few image paths for each class\n    print(\"Image paths for BlackSigatoka:\")\n    print(image_paths_blacksigatoka[:5])\n\n    print(\"\\nImage paths for FurasiumWilt:\")\n    print(image_paths_furasiumwilt[:5])\n\n    print(\"\\nImage paths for Cordana:\")\n    print(image_paths_cordana[:5])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T04:38:59.591633Z","iopub.execute_input":"2024-03-10T04:38:59.592029Z","iopub.status.idle":"2024-03-10T04:39:00.514912Z","shell.execute_reply.started":"2024-03-10T04:38:59.592002Z","shell.execute_reply":"2024-03-10T04:39:00.514068Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Image paths for BlackSigatoka:\n['/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka/257_jpeg.rf.3056e638b36d2805190c731d35590a75_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka/267_jpeg.rf.b449a72add174c60aaef9595acd9e1f0_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka/Image_1650_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka/Image_1672_aug_1.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka/202_jpeg.rf.4cae05ab9f7463e25bc30a6a4fdd0883_aug_0.png']\n\nImage paths for FurasiumWilt:\n['/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt/Image_3243_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt/Image_106_aug_1.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt/Image_2922_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt/Image_3277_aug_1.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt/Image_144_aug_1.png']\n\nImage paths for Cordana:\n['/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana/70_aug_1.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana/54_aug_1.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana/115_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana/132_aug_0.png', '/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana/9_aug_1.png']\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom skimage import exposure\nfrom tqdm import tqdm\n\ndef preprocess_images(file_paths, output_folder, target_size=(64, 64)):\n    # Ensure output folder exists\n    if not os.path.exists(output_folder):\n        os.makedirs(output_folder)\n\n    for path in tqdm(file_paths):\n        # Read the image\n        image = cv2.imread(path)\n\n        # Convert to grayscale\n        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n        # Apply Histogram Equalization to enhance contrast\n        equalized = exposure.equalize_hist(gray)\n\n        # Resize the image to a standard size\n        resized = cv2.resize(equalized, target_size)\n\n        # Normalize pixel values to be between 0 and 1\n        resized = resized / 255.0\n\n        # Save the preprocessed image\n        filename = os.path.basename(path)\n        output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_preprocessed.png\")\n        cv2.imwrite(output_path, (resized * 255).astype(np.uint8))\n\nif __name__ == \"__main__\":\n    # Specify input and output folders\n    input_folder_blacksigatoka = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka\"\n    input_folder_furasiumwilt = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt\"\n    input_folder_cordana = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana\"\n    output_folder_cordana = r\"/kaggle/working/BLD_augmented_data2/Cordana\"\n    output_folder_blacksigatoka = r\"/kaggle/working/BLD_augmented_data2/BlackSigatoka\"\n    output_folder_furasiumwilt = r\"/kaggle/working/BLD_augmented_data2/FurasiumWilt\"\n\n    # Get image paths for each class\n    image_paths_blacksigatoka = [os.path.join(input_folder_blacksigatoka, filename) for filename in os.listdir(input_folder_blacksigatoka)]\n    image_paths_furasiumwilt = [os.path.join(input_folder_furasiumwilt, filename) for filename in os.listdir(input_folder_furasiumwilt)]\n    image_paths_cordana = [os.path.join(input_folder_cordana, filename) for filename in os.listdir(input_folder_cordana)]\n\n    # Preprocess images\n    preprocess_images(image_paths_blacksigatoka, output_folder_blacksigatoka)\n    preprocess_images(image_paths_furasiumwilt, output_folder_furasiumwilt)\n    preprocess_images(image_paths_cordana, output_folder_cordana)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:07:15.210628Z","iopub.execute_input":"2024-03-10T05:07:15.211012Z","iopub.status.idle":"2024-03-10T05:09:00.139204Z","shell.execute_reply.started":"2024-03-10T05:07:15.210978Z","shell.execute_reply":"2024-03-10T05:09:00.138292Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"100%|██████████| 1008/1008 [00:44<00:00, 22.73it/s]\n100%|██████████| 1082/1082 [00:55<00:00, 19.48it/s]\n100%|██████████| 324/324 [00:04<00:00, 64.95it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"# import os\n# import cv2\n# import imgaug.augmenters as iaa\n# from tqdm import tqdm\n\n# def augment_images(input_folder, output_folder, num_copies=4):\n#     # Ensure output folder exists\n#     if not os.path.exists(output_folder):\n#         os.makedirs(output_folder)\n\n#     # Define augmentation pipeline\n#     seq = iaa.Sequential([\n#         iaa.Affine(rotate=(-90, 90)),        # 90-degree rotation\n#         iaa.Fliplr(1.0),                     # Flip left-right\n#         iaa.ShearX(shear=(-15, 15)),           # Shear rotation up to 10%\n#         iaa.Crop(percent=(0, 0.1)),           # Crop up to 10%\n#         iaa.Affine(rotate=(-180, 180)),\n#        #iaa.Affine(rotate=(-360, 360)),\n#         #iaa.Affine(scale=(0.8, 1.5)),\n#         #iaa.GaussianBlur(sigma=(0.0, 1.0)),\n#         #iaa.Multiply((0.8, 1.5), per_channel=0.2),\n#         #iaa.MultiplyHue((0.9, 1.6)),\n#     ])\n\n#     # Loop through each image in the input folder\n#     for filename in tqdm(os.listdir(input_folder)):\n#         if filename.endswith(('.png', '.jpg', '.jpeg')):\n#             image_path = os.path.join(input_folder, filename)\n\n#             # Read the image\n#             image = cv2.imread(image_path)\n\n#             # Apply augmentation and save augmented copies\n#             for i in range(num_copies):\n#                 augmented_image = seq.augment_image(image)\n#                 output_path = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}_aug_{i}.png\")\n#                 cv2.imwrite(output_path, augmented_image)\n\n# if __name__ == \"__main__\":\n#     # Specify input and output folders\n#     input_folder_blacksigatoka = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/BlackSigatoka\"\n#     input_folder_furasiumwilt = r\"/kaggle/input/blddisease-wise/BLD_augmented_data/FurasiumWilt\"\n#     input_folder_cordana=r\"/kaggle/input/blddisease-wise/BLD_augmented_data/Cordana\"\n#     output_folder_cordana=r\"/kaggle/working/BLD_augmented_data2/Cordana\"\n#     output_folder_blacksigatoka = r\"/kaggle/working/BLD_augmented_data2/BlackSigatoka\"\n#     output_folder_furasiumwilt = r\"/kaggle/working/BLD_augmented_data2/FurasiumWilt\"\n\n#     # Specify the number of copies per image\n#     #num_copies = 2\n\n#     # Perform augmentations\n#     augment_images(input_folder_blacksigatoka, output_folder_blacksigatoka, 2)\n#     augment_images(input_folder_furasiumwilt, output_folder_furasiumwilt, 2)\n#     augment_images(input_folder_cordana, output_folder_cordana, 8)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:09:00.140868Z","iopub.execute_input":"2024-03-10T05:09:00.141187Z","iopub.status.idle":"2024-03-10T05:09:00.146693Z","shell.execute_reply.started":"2024-03-10T05:09:00.141160Z","shell.execute_reply":"2024-03-10T05:09:00.145884Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"# import os\n# import cv2\n# import numpy as np\n# from sklearn.model_selection import train_test_split\n# # from sklearn.svm import SVC\n# from sklearn.metrics import accuracy_score\n# from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n# print(\"Succesfully imported packeges\")","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:09:00.147698Z","iopub.execute_input":"2024-03-10T05:09:00.148331Z","iopub.status.idle":"2024-03-10T05:09:00.161662Z","shell.execute_reply.started":"2024-03-10T05:09:00.148304Z","shell.execute_reply":"2024-03-10T05:09:00.160349Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# def extract_hog_lbp_features(image_path):\n#     image = io.imread(image_path, as_gray=True)\n#     image = (image * 255).astype(np.uint8)\n#     hog_features, _ = feature.hog(image, visualize=True, block_norm='L2-Hys')\n#     lbp_features = feature.local_binary_pattern(image, P=8, R=1, method='uniform')\n#     return np.concatenate((hog_features, lbp_features.flatten()))\n\n# batch_size = 50\n\n# # Extract HOG and LBP features for the training set\n# X_train_features = []\n\n# for i in range(0, len(X_train), batch_size):\n#     batch_images = X_train[i:i+batch_size]\n#     batch_features = [extract_hog_lbp_features(image_path) for image_path in batch_images]\n#     X_train_features.extend(batch_features)\n\n# # Extract HOG and LBP features for the testing set\n# X_test_features = []\n\n# for i in range(0, len(X_test), batch_size):\n#     batch_images = X_test[i:i+batch_size]\n#     batch_features = [extract_hog_lbp_features(image_path) for image_path in batch_images]\n#     X_test_features.extend(batch_features)\n\n# # Convert to NumPy arrays\n# hog_xfeatures_train = np.array(X_train_features)\n# lbp_xfeatures_train = np.array(X_test_features)\n\n# # Flatten the features\n# hog_features_flat_train = hog_xfeatures_train.flatten()\n# lbp_features_flat_train = lbp_xfeatures_train.flatten()\n\n# # Convert to NumPy arrays\n# hog_xfeatures_test = np.array(X_test_features)\n# lbp_xfeatures_test = np.array(X_test_features)\n\n# # Flatten the features\n# hog_features_flat_test = hog_xfeatures_test.flatten()\n# lbp_features_flat_test = lbp_xfeatures_test.flatten()\n\n# # Concatenate flattened features into a single vector\n# combined_features_train = np.concatenate((hog_features_flat_train, lbp_features_flat_train))\n\n# combined_features_test  = np.concatenate((hog_features_flat_test,lbp_features_flat_test))\n\n\n# # Print the shape of the combined features\n# print(\"Shape of combined features (training set):\", combined_features_train.shape)\n\n# print(\"Shape of combined features (training set):\", combined_features_test.shape)\n\n# # Print the first few values of the combined features\n# print(\"First few values of combined features (training set):\", combined_features_train[:])\n\n# print(\"Shape of combined features (training set):\", combined_features_test[:])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:09:00.163737Z","iopub.execute_input":"2024-03-10T05:09:00.164021Z","iopub.status.idle":"2024-03-10T05:09:00.173406Z","shell.execute_reply.started":"2024-03-10T05:09:00.163995Z","shell.execute_reply":"2024-03-10T05:09:00.172262Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"import os\nimport glob\nfrom skimage import io, feature\nimport numpy as np\n\ndef extract_hog_lbp_features(image_path):\n    image = io.imread(image_path, as_gray=True)\n    image = (image * 255).astype(np.uint8)\n    hog_features, _ = feature.hog(image, visualize=True, block_norm='L2-Hys')\n    lbp_features = feature.local_binary_pattern(image, P=8, R=1, method='uniform')\n    return np.concatenate((hog_features, lbp_features.flatten()))\n\ndef extract_features(input_folder):\n    file_paths = glob.glob(os.path.join(input_folder, '*.png'))\n\n    features = []\n    for image_path in file_paths:\n        feature_vector = extract_hog_lbp_features(image_path)\n        features.append(feature_vector)\n\n    return np.array(features)\n\nif __name__ == \"__main__\":\n    # Specify input and output folders\n    input_folder_blacksigatoka = r\"/kaggle/working/BLD_augmented_data2/BlackSigatoka\"\n    input_folder_furasiumwilt = r\"/kaggle/working/BLD_augmented_data2/FurasiumWilt\"\n    input_folder_cordana = r\"/kaggle/working/BLD_augmented_data2/Cordana\"\n\n    # Extract HOG and LBP features\n    hog_lbp_features_blacksigatoka = extract_features(input_folder_blacksigatoka)\n    hog_lbp_features_furasiumwilt = extract_features(input_folder_furasiumwilt)\n    hog_lbp_features_cordana = extract_features(input_folder_cordana)\n\n    # Print the shapes of the extracted features\n    print(\"Shape of HOG and LBP features (BlackSigatoka):\", hog_lbp_features_blacksigatoka.shape)\n    print(\"Shape of HOG and LBP features (FurasiumWilt):\", hog_lbp_features_furasiumwilt.shape)\n    print(\"Shape of HOG and LBP features (Cordana):\", hog_lbp_features_cordana.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:09:00.174883Z","iopub.execute_input":"2024-03-10T05:09:00.175493Z","iopub.status.idle":"2024-03-10T05:09:38.029417Z","shell.execute_reply.started":"2024-03-10T05:09:00.175466Z","shell.execute_reply":"2024-03-10T05:09:38.028269Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Shape of HOG and LBP features (BlackSigatoka): (1008, 7012)\nShape of HOG and LBP features (FurasiumWilt): (1082, 7012)\nShape of HOG and LBP features (Cordana): (324, 7012)\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nimport glob\nfrom skimage import io, feature\nimport numpy as np\n\nX_train = []  # Initialize X_train\ny_train = []  # Initialize y_train\n\ndef extract_hog_lbp_features(image_path):\n    image = io.imread(image_path, as_gray=True)\n    image = (image * 255).astype(np.uint8)\n    hog_features, _ = feature.hog(image, visualize=True, block_norm='L2-Hys')\n    lbp_features = feature.local_binary_pattern(image, P=8, R=1, method='uniform')\n    return np.concatenate((hog_features, lbp_features.flatten()))\n\ndef extract_features(input_folder):\n    file_paths = glob.glob(os.path.join(input_folder, '*.png'))\n    for image_path in file_paths:\n        features = extract_hog_lbp_features(image_path)\n        X_train.append(features)\n        # Assuming the label is the name of the class folder\n        label = os.path.basename(os.path.dirname(image_path))\n        y_train.append(label)\n\nif __name__ == \"__main__\":\n    # Specify input and output folders\n    input_folder_blacksigatoka = r\"/kaggle/working/BLD_augmented_data2/BlackSigatoka\"\n    input_folder_furasiumwilt = r\"/kaggle/working/BLD_augmented_data2/FurasiumWilt\"\n    input_folder_cordana = r\"/kaggle/working/BLD_augmented_data2/Cordana\"\n\n    # Extract HOG and LBP features\n    extract_features(input_folder_blacksigatoka)\n    extract_features(input_folder_furasiumwilt)\n    extract_features(input_folder_cordana)\n\n    # Convert lists to arrays\n    X_train_array = np.array(X_train)\n    y_train_array = np.array(y_train)\n\n    # Concatenate features and labels\n    all_features = np.column_stack((X_train_array, y_train_array))\n\n    # Flatten the features\n    flattened_features = all_features.flatten()\n\n    # Print the shapes of the extracted features\n    print(\"Shape of HOG and LBP features (All Classes):\", X_train_array.shape)\n    print(\"Shape of labels (All Classes):\", y_train_array.shape)\n    print(\"Shape of concatenated features and labels:\", all_features.shape)\n    print(\"Shape of flattened features (All Classes):\", flattened_features.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:18:58.444832Z","iopub.execute_input":"2024-03-10T05:18:58.445277Z","iopub.status.idle":"2024-03-10T05:19:40.751602Z","shell.execute_reply.started":"2024-03-10T05:18:58.445240Z","shell.execute_reply":"2024-03-10T05:19:40.750615Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Shape of HOG and LBP features (All Classes): (2414, 7012)\nShape of labels (All Classes): (2414,)\nShape of concatenated features and labels: (2414, 7013)\nShape of flattened features (All Classes): (16929382,)\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nfrom skimage import feature, io\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:22:44.774679Z","iopub.execute_input":"2024-03-10T05:22:44.775062Z","iopub.status.idle":"2024-03-10T05:22:57.920891Z","shell.execute_reply.started":"2024-03-10T05:22:44.775028Z","shell.execute_reply":"2024-03-10T05:22:57.919891Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# def load_data(folder_paths, label_mapping):\n#     X = []\n#     y = []\n\n#     for label, folder_key in label_mapping.items():\n#         class_folder = os.path.join(folder_paths[folder_key], label)\n#         features = extract_features(class_folder)  # Modify this to your extraction function\n#         labels = [label] * len(features)\n\n#         X.extend(features)\n#         y.extend(labels)\n\n#     return np.array(X), np.array(y)\n\n# if __name__ == \"__main__\":\n#     # Specify input folders\n#     folder_paths = {\n#         'BlackSigatoka': 'BlackSigatoka',\n#         'FurasiumWilt': 'FurasiumWilt',\n#         'Cordana': 'Cordana'\n#     }\n\n#     # Specify label mapping\n#     label_mapping = {'BlackSigatoka': 'BlackSigatoka', 'FurasiumWilt': 'FurasiumWilt', 'Cordana': 'Cordana'}\n\n#     # Load data\n#     X, y = load_data(folder_paths, label_mapping)\n\n#     # Print the shape of loaded data\n#     print(\"Shape of features:\", X.shape)\n#     print(\"Shape of labels:\", y.shape)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:23:30.960360Z","iopub.execute_input":"2024-03-10T05:23:30.961031Z","iopub.status.idle":"2024-03-10T05:23:30.966656Z","shell.execute_reply.started":"2024-03-10T05:23:30.961000Z","shell.execute_reply":"2024-03-10T05:23:30.965538Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Apply z-score normalization\nscaler = StandardScaler()\nX_train_normalized = scaler.fit_transform(X_train_array)\nall_features = np.column_stack((X_train_normalized, y_train_array))\n\n# Print the shape and first few values of the normalized features\nprint(\"Shape of normalized features (training set):\", X_train_normalized.shape)\nprint(\"Shape of all features:\", all_features.shape)\nprint(\"First few values of all features:\", all_features[:])\nprint(\"First few values of normalized features (training set):\", X_train_normalized[:])","metadata":{"execution":{"iopub.status.busy":"2024-03-10T05:33:18.555159Z","iopub.execute_input":"2024-03-10T05:33:18.555541Z","iopub.status.idle":"2024-03-10T05:33:27.160841Z","shell.execute_reply.started":"2024-03-10T05:33:18.555512Z","shell.execute_reply":"2024-03-10T05:33:27.159651Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Shape of normalized features (training set): (2414, 7012)\nShape of all features: (2414, 7013)\nFirst few values of all features: [['-0.16912662598197656' '0.0' '-0.11398855726176177' ...\n  '0.041981492915668925' '0.04324788304874349' 'BlackSigatoka']\n ['-0.16912662598197656' '0.0' '-0.11398855726176177' ...\n  '0.041981492915668925' '0.04324788304874349' 'BlackSigatoka']\n ['-0.16912662598197656' '0.0' '-0.11398855726176177' ...\n  '0.041981492915668925' '0.04324788304874349' 'BlackSigatoka']\n ...\n ['-0.16912662598197656' '0.0' '-0.11398855726176177' ...\n  '0.041981492915668925' '0.04324788304874349' 'Cordana']\n ['-0.16912662598197656' '0.0' '-0.11398855726176177' ...\n  '0.041981492915668925' '0.04324788304874349' 'Cordana']\n ['-0.16912662598197656' '0.0' '-0.11398855726176177' ...\n  '0.041981492915668925' '0.04324788304874349' 'Cordana']]\nFirst few values of normalized features (training set): [[-0.16912663  0.         -0.11398856 ...  0.04834056  0.04198149\n   0.04324788]\n [-0.16912663  0.         -0.11398856 ...  0.04834056  0.04198149\n   0.04324788]\n [-0.16912663  0.         -0.11398856 ...  0.04834056  0.04198149\n   0.04324788]\n ...\n [-0.16912663  0.         -0.11398856 ...  0.04834056  0.04198149\n   0.04324788]\n [-0.16912663  0.         -0.11398856 ...  0.04834056  0.04198149\n   0.04324788]\n [-0.16912663  0.         -0.11398856 ...  0.04834056  0.04198149\n   0.04324788]]\n","output_type":"stream"}]},{"cell_type":"code","source":"import glob\nfrom sklearn.model_selection import train_test_split\n\n# Now, let's split the data\nX_train_split, X_test_split, y_train_split, y_test_split = train_test_split(X_train_normalized, y_train, test_size=0.2, random_state=42)\n\n# Print the sizes of the training and testing sets\nprint(f\"Training set size: {len(X_train)}\")\nprint(f\"Testing set size: {len(X_test)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-03-10T04:39:01.243295Z","iopub.status.idle":"2024-03-10T04:39:01.243542Z","shell.execute_reply.started":"2024-03-10T04:39:01.243416Z","shell.execute_reply":"2024-03-10T04:39:01.243428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def extract_hog_lbp_features(image_path):\n#     image = io.imread(image_path, as_gray=True)\n#     image = (image * 255).astype(np.uint8)\n#     hog_features, _ = feature.hog(image, visualize=True, block_norm='L2-Hys')\n#     lbp_features = feature.local_binary_pattern(image, P=8, R=1, method='uniform')\n#     return np.concatenate((hog_features, lbp_features.flatten()))\n\n# batch_size = 50\n\n# # Extract HOG and LBP features for the training set\n# X_train_features = []\n\n# for i in range(0, len(X_train), batch_size):\n#     batch_images = X_train[i:i+batch_size]\n#     batch_features = [extract_hog_lbp_features(image_path) for image_path in batch_images]\n#     X_train_features.extend(batch_features)\n\n# # Extract HOG and LBP features for the testing set\n# X_test_features = []\n\n# for i in range(0, len(X_test), batch_size):\n#     batch_images = X_test[i:i+batch_size]\n#     batch_features = [extract_hog_lbp_features(image_path) for image_path in batch_images]\n#     X_test_features.extend(batch_features)\n\n# # Convert to NumPy arrays\n# hog_xfeatures_train = np.array(X_train_features)\n# lbp_xfeatures_train = np.array(X_test_features)\n\n# # Flatten the features\n# hog_features_flat_train = hog_xfeatures_train.flatten()\n# lbp_features_flat_train = lbp_xfeatures_train.flatten()\n\n# # Convert to NumPy arrays\n# hog_xfeatures_test = np.array(X_test_features)\n# lbp_xfeatures_test = np.array(X_test_features)\n\n# # Flatten the features\n# hog_features_flat_test = hog_xfeatures_test.flatten()\n# lbp_features_flat_test = lbp_xfeatures_test.flatten()\n\n# # Concatenate flattened features into a single vector\n# combined_features_train = np.concatenate((hog_features_flat_train, lbp_features_flat_train))\n\n# combined_features_test  = np.concatenate((hog_features_flat_test,lbp_features_flat_test))\n\n\n# # Print the shape of the combined features\n# print(\"Shape of combined features (training set):\", combined_features_train.shape)\n\n# print(\"Shape of combined features (training set):\", combined_features_test.shape)\n\n# # Print the first few values of the combined features\n# print(\"First few values of combined features (training set):\", combined_features_train[:])\n\n# print(\"Shape of combined features (training set):\", combined_features_test[:])\n","metadata":{"execution":{"iopub.status.busy":"2024-03-03T12:18:55.788921Z","iopub.status.idle":"2024-03-03T12:18:55.789350Z","shell.execute_reply.started":"2024-03-03T12:18:55.789136Z","shell.execute_reply":"2024-03-03T12:18:55.789156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(X_train))","metadata":{"execution":{"iopub.status.busy":"2024-03-03T12:18:55.791152Z","iopub.status.idle":"2024-03-03T12:18:55.791587Z","shell.execute_reply.started":"2024-03-03T12:18:55.791356Z","shell.execute_reply":"2024-03-03T12:18:55.791376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncolumn1=['categorical_feature1']\ndf1 = pd.DataFrame(combined_features_train,columns=column1)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.514872Z","iopub.status.idle":"2024-02-29T15:46:19.515541Z","shell.execute_reply.started":"2024-02-29T15:46:19.515331Z","shell.execute_reply":"2024-02-29T15:46:19.515351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df1.columns)\nprint(df1.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.516689Z","iopub.status.idle":"2024-02-29T15:46:19.517318Z","shell.execute_reply.started":"2024-02-29T15:46:19.517115Z","shell.execute_reply":"2024-02-29T15:46:19.517134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n#df1['categorical_feature1'] = df1['categorical_feature1'].astype('category')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.518405Z","iopub.status.idle":"2024-02-29T15:46:19.518761Z","shell.execute_reply.started":"2024-02-29T15:46:19.518593Z","shell.execute_reply":"2024-02-29T15:46:19.518610Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\n#df1['categorical_feature1'] = pd.Categorical(df1['categorical_feature1'])\n#df1['categorical_feature1'] = df1['categorical_feature1'].cat.codes","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.519822Z","iopub.status.idle":"2024-02-29T15:46:19.520472Z","shell.execute_reply.started":"2024-02-29T15:46:19.520254Z","shell.execute_reply":"2024-02-29T15:46:19.520279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ncolumn2=['categorical_feature2']\ndf2 = pd.DataFrame(combined_features_test,columns=column2)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.521691Z","iopub.status.idle":"2024-02-29T15:46:19.522026Z","shell.execute_reply.started":"2024-02-29T15:46:19.521861Z","shell.execute_reply":"2024-02-29T15:46:19.521877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df2.columns)\nprint(df2.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.523123Z","iopub.status.idle":"2024-02-29T15:46:19.523842Z","shell.execute_reply.started":"2024-02-29T15:46:19.523652Z","shell.execute_reply":"2024-02-29T15:46:19.523672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_types=df2.dtypes\nprint(column_types)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.524970Z","iopub.status.idle":"2024-02-29T15:46:19.525309Z","shell.execute_reply.started":"2024-02-29T15:46:19.525144Z","shell.execute_reply":"2024-02-29T15:46:19.525160Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\n#df2['categorical_feature2'] = df2['categorical_feature2'].astype('category')","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.526695Z","iopub.status.idle":"2024-02-29T15:46:19.527430Z","shell.execute_reply.started":"2024-02-29T15:46:19.527239Z","shell.execute_reply":"2024-02-29T15:46:19.527258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming df is your DataFrame\n#df2['categorical_feature2'] = pd.Categorical(df2['categorical_feature2'])\n#df2['categorical_feature2'] = df2['categorical_feature2'].cat.codes","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.528251Z","iopub.status.idle":"2024-02-29T15:46:19.528598Z","shell.execute_reply.started":"2024-02-29T15:46:19.528417Z","shell.execute_reply":"2024-02-29T15:46:19.528433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df2.dtypes)\nprint(df2.head())","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.530048Z","iopub.status.idle":"2024-02-29T15:46:19.530407Z","shell.execute_reply.started":"2024-02-29T15:46:19.530237Z","shell.execute_reply":"2024-02-29T15:46:19.530254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Plot histograms for HOG and LBP features\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(12, 6))\n\nplt.subplot(2, 2, 1)\nplt.hist(hog_features_flat_train, bins=50, color='blue', alpha=0.7)\nplt.title('HOG Features Histogram (Training Set)')\n\nplt.subplot(2, 2, 2)\nplt.hist(lbp_features_flat_train, bins=50, color='green', alpha=0.7)\nplt.title('LBP Features Histogram (Training Set)')\n\nplt.subplot(2, 2, 3)\nplt.hist(hog_features_flat_test, bins=50, color='blue', alpha=0.7)\nplt.title('HOG Features Histogram (Testing Set)')\n\nplt.subplot(2, 2, 4)\nplt.hist(lbp_features_flat_test, bins=50, color='green', alpha=0.7)\nplt.title('LBP Features Histogram (Testing Set)')\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.531683Z","iopub.status.idle":"2024-02-29T15:46:19.532027Z","shell.execute_reply.started":"2024-02-29T15:46:19.531858Z","shell.execute_reply":"2024-02-29T15:46:19.531875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"numpy_array=df1.values","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.533069Z","iopub.status.idle":"2024-02-29T15:46:19.533420Z","shell.execute_reply.started":"2024-02-29T15:46:19.533254Z","shell.execute_reply":"2024-02-29T15:46:19.533270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"NumPy Array:\")\nprint(numpy_array)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.534453Z","iopub.status.idle":"2024-02-29T15:46:19.535004Z","shell.execute_reply.started":"2024-02-29T15:46:19.534818Z","shell.execute_reply":"2024-02-29T15:46:19.534837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(numpy_array)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.536308Z","iopub.status.idle":"2024-02-29T15:46:19.536657Z","shell.execute_reply.started":"2024-02-29T15:46:19.536477Z","shell.execute_reply":"2024-02-29T15:46:19.536493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train_scaled)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.537597Z","iopub.status.idle":"2024-02-29T15:46:19.537928Z","shell.execute_reply.started":"2024-02-29T15:46:19.537763Z","shell.execute_reply":"2024-02-29T15:46:19.537779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert y_train, y_val, and y to NumPy arrays\ny_train = np.array(y_train)\ny_test = np.array(y_test)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.538996Z","iopub.status.idle":"2024-02-29T15:46:19.539579Z","shell.execute_reply.started":"2024-02-29T15:46:19.539376Z","shell.execute_reply":"2024-02-29T15:46:19.539397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom itertools import product","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.540691Z","iopub.status.idle":"2024-02-29T15:46:19.541038Z","shell.execute_reply.started":"2024-02-29T15:46:19.540869Z","shell.execute_reply":"2024-02-29T15:46:19.540886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(128, input_dim=12800, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(units=1, activation='sigmoid'))\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.542145Z","iopub.status.idle":"2024-02-29T15:46:19.542575Z","shell.execute_reply.started":"2024-02-29T15:46:19.542388Z","shell.execute_reply":"2024-02-29T15:46:19.542406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"X_train_scaled shape:\", X_train_scaled.shape)\nprint(\"y_train shape:\", np.array(y_train).shape)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.543874Z","iopub.status.idle":"2024-02-29T15:46:19.544537Z","shell.execute_reply.started":"2024-02-29T15:46:19.544307Z","shell.execute_reply":"2024-02-29T15:46:19.544329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train_scaled,y_train,epochs=50, batch_size=50)","metadata":{"execution":{"iopub.status.busy":"2024-02-29T15:46:19.545917Z","iopub.status.idle":"2024-02-29T15:46:19.546402Z","shell.execute_reply.started":"2024-02-29T15:46:19.546216Z","shell.execute_reply":"2024-02-29T15:46:19.546237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}