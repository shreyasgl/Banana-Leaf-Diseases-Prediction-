{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1PXom1_9BxFRRJc2x0j0E2-bG1x8w6-V7","timestamp":1703504028592}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Lc7Rn3-cUvc4","executionInfo":{"status":"ok","timestamp":1722404641185,"user_tz":-330,"elapsed":39765,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}},"outputId":"7095676c-9de4-47c5-afb0-eebc7fab44a2","colab":{"base_uri":"https://localhost:8080/"}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","import glob\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"L4b0AwcPmwyB","executionInfo":{"status":"ok","timestamp":1722404642661,"user_tz":-330,"elapsed":1483,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["!pip install category_encoders"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsOGTC6OVC_L","executionInfo":{"status":"ok","timestamp":1722404646414,"user_tz":-330,"elapsed":3757,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}},"outputId":"1ec0e47d-ff03-4c27-fdd6-e98e4091ce84"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting category_encoders\n","  Downloading category_encoders-2.6.3-py2.py3-none-any.whl.metadata (8.0 kB)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.26.4)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.3.2)\n","Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (1.13.1)\n","Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.14.2)\n","Requirement already satisfied: pandas>=1.0.5 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (2.1.4)\n","Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.10/dist-packages (from category_encoders) (0.5.6)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.5->category_encoders) (2024.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.5.1->category_encoders) (1.16.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->category_encoders) (3.5.0)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.9.0->category_encoders) (24.1)\n","Downloading category_encoders-2.6.3-py2.py3-none-any.whl (81 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/81.9 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: category_encoders\n","Successfully installed category_encoders-2.6.3\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.metrics import accuracy_score\n","from category_encoders import OrdinalEncoder"],"metadata":{"id":"c08iusbiU9Ea","executionInfo":{"status":"ok","timestamp":1722404648793,"user_tz":-330,"elapsed":1673,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["import zipfile\n","import os\n","import glob\n","\n","# Define the path to your local dataset\n","dataset_path = '/content/drive/MyDrive/CurrentWorkingDataset(500-WBG).zip'\n","\n","# Specify the extraction directory\n","extracted_path = '/content/extracted/'\n","\n","# Create the target directory if it doesn't exist\n","!mkdir -p $extracted_path\n","\n","# Unzip the file\n","with zipfile.ZipFile(dataset_path, 'r') as zip_ref:\n","    zip_ref.extractall(extracted_path)\n","\n","# Specify the classes\n","classes = ['healthy', 'unhealthy']\n","\n","# Initialize empty lists to store file paths and labels\n","file_paths = []\n","labels = []\n","\n","# Access files in each class\n","for class_name in classes:\n","    class_path = os.path.join(extracted_path, class_name)\n","    files = glob.glob(os.path.join(class_path, '*.jpg'))  # Assuming the images are in JPG format\n","\n","    # Append file paths and corresponding labels\n","    file_paths.extend(files)\n","    labels.extend([class_name] * len(files))\n","\n","# Display the first few file paths and labels\n","for path, label in zip(file_paths[:5], labels[:5]):\n","    print(f\"File Path: {path}, Label: {label}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5Y5Z02krVVX-","executionInfo":{"status":"ok","timestamp":1722404653197,"user_tz":-330,"elapsed":4414,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}},"outputId":"c1721d1c-afcf-4ecf-a42e-ed4ae34303df"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["File Path: /content/extracted/healthy/Image_258.jpg, Label: healthy\n","File Path: /content/extracted/healthy/Healthy Leaf (49).jpg, Label: healthy\n","File Path: /content/extracted/healthy/Image_326.jpg, Label: healthy\n","File Path: /content/extracted/healthy/Image_2962.jpg, Label: healthy\n","File Path: /content/extracted/healthy/Image_2927.jpg, Label: healthy\n"]}]},{"cell_type":"code","source":["print(f\"Length of file_paths: {len(file_paths)}\")\n","print(f\"Length of labels: {len(labels)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XEx_nsnxV2xz","executionInfo":{"status":"ok","timestamp":1722404653198,"user_tz":-330,"elapsed":31,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}},"outputId":"1b00c796-c5e1-4e94-a5aa-526af53bf5a5"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Length of file_paths: 760\n","Length of labels: 760\n"]}]},{"cell_type":"code","source":["import numpy as np\n","from skimage import feature, io\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.metrics import accuracy_score\n","from tensorflow import keras\n","from tensorflow.keras import layers"],"metadata":{"id":"xXXoiNKxWek3","executionInfo":{"status":"ok","timestamp":1722404660853,"user_tz":-330,"elapsed":7679,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from skimage import exposure\n","\n","def preprocess_images(file_paths, labels, target_size=(64, 64)):\n","    processed_images = []\n","    processed_labels = []\n","\n","    for path, label in zip(file_paths, labels):\n","        # Read the image\n","        image = cv2.imread(path)\n","\n","        # Convert to grayscale\n","        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","        # Apply Histogram Equalization to enhance contrast\n","        equalized = exposure.equalize_hist(gray)\n","\n","        # Resize the image to a standard size\n","        resized = cv2.resize(equalized, target_size)\n","\n","        # Normalize pixel values to be between 0 and 1\n","        resized = resized / 255.0\n","\n","        # Perform additional preprocessing if needed\n","        # ...\n","\n","        # Append the preprocessed image and label\n","        processed_images.append(resized)\n","        processed_labels.append(label)\n","\n","    return np.array(processed_images), np.array(processed_labels)\n","\n","# Specify the target size for resizing\n","target_size = (64, 64)\n","\n","# Preprocess the images\n","X, y = preprocess_images(file_paths, labels, target_size=target_size)\n","\n","# Display the shapes of the preprocessed data\n","print(\"Shape of preprocessed images:\", X.shape)\n","print(\"Shape of labels:\", y.shape)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vYGxOyOHWiVc","executionInfo":{"status":"ok","timestamp":1722404686475,"user_tz":-330,"elapsed":25626,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}},"outputId":"59862ea0-38e9-4c27-b880-d4a6798653e8"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of preprocessed images: (760, 64, 64)\n","Shape of labels: (760,)\n"]}]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from skimage import feature\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","import os\n","\n","def extract_features(image):\n","    # Extract HOG features\n","    hog_features = feature.hog(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2), transform_sqrt=True, block_norm='L2-Hys')\n","\n","    # Extract LBP features\n","    lbp_radius = 3\n","    lbp_points = 8 * lbp_radius\n","    lbp_features = feature.local_binary_pattern(image, lbp_points, lbp_radius, method='uniform')\n","\n","    return hog_features, lbp_features.flatten()\n","\n","def load_preprocessed_images(file_paths, labels):\n","    images = []\n","    for path in file_paths:\n","        # Read the preprocessed image\n","        image = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n","\n","        if image is not None:\n","            images.append(image)\n","\n","    return images, labels\n","\n","# Specify the path to the folder containing preprocessed images\n","preprocessed_folder_path = '/content/extracted/'\n","\n","# Load preprocessed images\n","preprocessed_images, labels = load_preprocessed_images(file_paths, labels)\n","\n","# Extract features for each preprocessed image\n","features = []\n","for image in preprocessed_images:\n","    hog_features, lbp_features = extract_features(image)\n","    features.append(np.concatenate((hog_features, lbp_features)))\n","\n","# Convert the list of features to a NumPy array\n","X = np.array(features)\n","y = np.array(labels)\n","\n","# Split the dataset into training and testing sets\n","#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"],"metadata":{"id":"-XvMMdJgcypI","colab":{"base_uri":"https://localhost:8080/","height":228},"executionInfo":{"status":"error","timestamp":1722404899702,"user_tz":-330,"elapsed":213255,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}},"outputId":"fa121aae-48c0-4cfd-bbb5-16c9ed265aa9"},"execution_count":9,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (760,) + inhomogeneous part.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-994b75f874ff>\u001b[0m in \u001b[0;36m<cell line: 45>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Convert the list of features to a NumPy array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (760,) + inhomogeneous part."]}]},{"cell_type":"code","source":["def load_data(folder_path):\n","    X = []\n","    y = []\n","    label_mapping = {'healthy': 0, 'unhealthy': 1}\n","    count = 0\n","\n","    for label in label_mapping.keys():\n","        label_folder = os.path.join(folder_path, label)\n","        for filename in os.listdir(label_folder):\n","            if filename.endswith(\".png\"):\n","                count += 1\n","                image_path = os.path.join(label_folder, filename)\n","                print(\"Extracting features from \" + label_folder + \" image number \" + str(count))\n","\n","                # Preprocess the image\n","                preprocessed_image = preprocess_single_image(image_path, target_size=target_size)\n","\n","                # Extract HOG and LBP features\n","                features = extract_hog_lbp_features(preprocessed_image)\n","\n","                # Append the features and labels to X and y\n","                X.append(features)\n","                y.append(label_mapping[label])\n","\n","    return X, y\n"],"metadata":{"id":"whJWjw9YWk7V","executionInfo":{"status":"aborted","timestamp":1722404899704,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["xyz='/content/extracted/'"],"metadata":{"id":"Hh0fXm6VfoC4","executionInfo":{"status":"aborted","timestamp":1722404899704,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["labels=np.array(y)\n","len(labels)"],"metadata":{"id":"YTbq1o-bWn2o","executionInfo":{"status":"aborted","timestamp":1722404899705,"user_tz":-330,"elapsed":17,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","labels=np.array(y)\n","\n","# Initialize an empty list for the converted labels\n","converted_labels = []\n","\n","# Loop through the original labels and convert them\n","for label in labels:\n","    if label == 'healthy':\n","        converted_labels.append(1)\n","    elif label == 'unhealthy':\n","        converted_labels.append(0)\n","\n","# Convert the list to a NumPy array\n","labels = np.array(converted_labels)\n","\n","# Print the resulting labels\n","print(labels)\n","len(labels)"],"metadata":{"id":"XwrJOlaNpp1X","executionInfo":{"status":"aborted","timestamp":1722404899705,"user_tz":-330,"elapsed":17,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["max_length = max(len(x) for x in X)\n","X_padded = [np.pad(x, (0, max_length - len(x))) for x in X]\n","features = np.array(X_padded)"],"metadata":{"id":"cJhMhSm9ZkEN","executionInfo":{"status":"aborted","timestamp":1722404899705,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y"],"metadata":{"id":"ejuQGgzsrIRo","executionInfo":{"status":"aborted","timestamp":1722404899705,"user_tz":-330,"elapsed":15,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# Split the data into train and validation sets\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=y)"],"metadata":{"id":"hXF5T4SjZnGq","executionInfo":{"status":"aborted","timestamp":1722404899706,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(features)\n","\n","X_test_scaled = scaler.transform(X_test)"],"metadata":{"id":"WifO-p68aoCb","executionInfo":{"status":"aborted","timestamp":1722404899706,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert y_train, y_val, and y to NumPy arrays\n","y_train = np.array(y_train)\n","y_test = np.array(y_test)\n","y = np.array(y)"],"metadata":{"id":"1ShG7TKTauSD","executionInfo":{"status":"aborted","timestamp":1722404899706,"user_tz":-330,"elapsed":15,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"kjv7RaQkpSgo","executionInfo":{"status":"aborted","timestamp":1722404899706,"user_tz":-330,"elapsed":15,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from itertools import product"],"metadata":{"id":"o-6Fbt21ayTV","executionInfo":{"status":"aborted","timestamp":1722404899707,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","    # model = Sequential()\n","    # model.add(Dense(128, input_dim=12800, activation='relu'))\n","    # model.add(Dense(64, activation='relu'))\n","    # model.add(Dense(units=1, activation='sigmoid'))\n","    # model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"],"metadata":{"id":"6BmTCuDka1jD","executionInfo":{"status":"aborted","timestamp":1722404899707,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["features"],"metadata":{"id":"lzJdzzpPsctR","executionInfo":{"status":"aborted","timestamp":1722404899707,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import StratifiedKFold\n","import matplotlib.pyplot as plt\n","\n","# Step 1: Split the data into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42, stratify=y)\n","\n","# Step 2: Scale the data\n","scaler = StandardScaler()\n","X_train_scaled = scaler.fit_transform(X_train)\n","X_test_scaled = scaler.transform(X_test)\n","\n","# len(X_train_scaled)\n","# len(X_test_scaled)\n","\n","len(X_train_scaled[0])"],"metadata":{"id":"aFyt30_wa4BY","executionInfo":{"status":"aborted","timestamp":1722404899707,"user_tz":-330,"elapsed":15,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Step 3: Create the ANN model\n","model = Sequential()\n","model.add(Dense(128, input_dim=324108, activation='relu'))\n","model.add(Dense(64, activation='relu'))\n","model.add(Dense(units=1, activation='sigmoid'))\n","model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Step 4: Use StratifiedKFold for stratified cross-validation in classification problems\n","cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","accuracy_scores = []\n","\n","# Step 5: Iterate over folds for cross-validation\n","for train_index, val_index in cv.split(X_train_scaled, y_train):\n","    X_train_fold, X_val_fold = X_train_scaled[train_index], X_train_scaled[val_index]\n","    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]\n","\n","    # Create and train the model\n","    history = model.fit(X_train_fold, y_train_fold, epochs=10, batch_size=8, verbose=0, validation_data=(X_val_fold, y_val_fold))\n","\n","    # Plot learning curve\n","    plt.plot(history.history['accuracy'], label='train_accuracy')\n","    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy')\n","    plt.title('Learning Curve')\n","    plt.legend()\n","    plt.show()\n","\n","    # Evaluate on the validation set\n","    _, accuracy = model.evaluate(X_val_fold, y_val_fold, verbose=0)\n","    accuracy_scores.append(accuracy)\n","    print(f\"Fold Accuracy: {accuracy * 100:.2f}%\")\n","\n","# Step 6: Print the mean accuracy across folds\n","print(\"Mean Accuracy during Cross-Validation:\", np.mean(accuracy_scores))\n","\n","# Step 7: Evaluate on the separate test set\n","test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n","print(\"Test Accuracy on Separate Test Set:\", test_accuracy)\n"],"metadata":{"id":"Y8N9RIvqtdKD","executionInfo":{"status":"aborted","timestamp":1722404899708,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.svm import SVC\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import accuracy_score\n","\n","# Step 3: Create the SVM model\n","svm_model = SVC()\n","\n","# Step 4: Define hyperparameter grid for tuning\n","param_grid = {\n","    'C': [0.1, 1, 10, 100],  # Regularization parameter\n","    'kernel': ['linear', 'rbf', 'poly'],  # Kernel type\n","    'gamma': ['scale', 'auto', 0.1, 1],  # Kernel coefficient\n","}\n","\n","# Step 5: Use StratifiedKFold for stratified cross-validation\n","cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n","\n","# Step 6: Perform hyperparameter tuning using GridSearchCV\n","grid_search = GridSearchCV(svm_model, param_grid, cv=cv, scoring='accuracy', verbose=1)\n","grid_search.fit(X_train_scaled, y_train)\n","\n","# Step 7: Display the best hyperparameters\n","best_params = grid_search.best_params_\n","print(\"Best Hyperparameters:\", best_params)\n","\n","# Step 8: Access the best model\n","best_svm_model = grid_search.best_estimator_\n","\n","# Step 9: Evaluate on the separate test set\n","y_test_pred = best_svm_model.predict(X_test_scaled)\n","test_accuracy = accuracy_score(y_test, y_test_pred)\n","print(\"Test Accuracy on Separate Test Set:\", test_accuracy)\n"],"metadata":{"id":"cBjYyzb6miES","executionInfo":{"status":"aborted","timestamp":1722404899708,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uCqSA-TDbfC2","executionInfo":{"status":"aborted","timestamp":1722404899708,"user_tz":-330,"elapsed":16,"user":{"displayName":"shreyas jadhav","userId":"08848487352368149299"}}},"execution_count":null,"outputs":[]}]}